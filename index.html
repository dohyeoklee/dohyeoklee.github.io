<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Dohyeok Lee</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Dohyeok Lee
                </p>
                <p>
                  I'm a Ph.D. student in Electrical and Computer Engineering at <a href="https://en.snu.ac.kr/index.html/">Seoul National University (SNU)</a>, advised by <a href="https://cml.snu.ac.kr/">Prof. Jungwoo Lee</a>.  
                  Currently, I am a visiting researcher working with <a href="https://sites.google.com/site/tapomayukh">Prof. Tapomayukh Bhattacharjee</a> at Cornell University.
                </p>
                <p>
                  Previously, I received my M.S. in ECE from SNU in 2024 and B.S. in <a href="https://ee.kaist.ac.kr/en/">EE</a> from <a href="https://www.kaist.ac.kr/en/">KAIST</a> in 2020.
                </p>
                <p>
                  <strong>Research Keywords</strong>: Robot Learning, Robotics, Learning from Demonstration (LfD), Reinforcement Learning (RL).
                </p>

                <p style="text-align:center">
                  <a href="mailto:dohyeoklee.kr@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_dhlee.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=RcFFkMYAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/dohyeoklee/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/dohyeoklee/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile_4.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile_4.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
          <h2>Research Vision</h2>
          <p class="research-question">
            <strong>How can we leverage physics understanding to make robot learning truly generalizable?</strong>
          </p>
          <p>
            My research focuses on empowering robots with physical understanding for robust generalization: when agents truly understand the physics and affordances of their environment, they can adapt beyond their training distribution.
            This pursuit rests on a core assumption: unlike language (a human abstraction), <strong>nature has law</strong> - and these principles can be learned and leveraged.<br>
          </p>
          <p>
            This leads to two fundamental questions.
          </p>
          <ul>
            <li><strong>How do we represent physics?</strong> I combine novel view synthesis and dynamics prediction to enable informed decisions on unseen data.</li>
            <li><strong>How do we achieve understanding beyond prediction?</strong> I aim to build systems that internalize causal structure, not merely forecast outcomes.</li>
          </ul>
          <p>
            My vision is to create robotic systems that discover underlying principles to solve any fine manipulation task with human-level dexterity and adaptability.
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/spqr_concept.jpg" alt="PontTuset" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/cdcaf772b4f8eda0385d0930517de64a-Abstract-Conference.html" id="MCG_journal">
                  <span class="papertitle">SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning</span>
                </a>
                <br>
                <strong>Dohyeok Lee</strong>, <a href="https://hansungy.github.io/">Seungyub Han</a>, Taehyun Cho, Jungwoo Lee
                <br>
                <em>NeurIPS</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2401.03137/">paper</a> /
                <a href="https://github.com/dohyeoklee/SPQR">code</a>
                <p></p>
                <p>
                  We proposed SPQR, the first theoretically-grounded independence regularization for ensemble Q-learning based on <strong>random matrix theory</strong>. 
                  By ensuring proper independence, our approach significantly improves <strong>generalization to out-of-distribution data</strong> across diverse RL tasks.
                </p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/arte.png" alt="PontTuset" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">ARTificial Expressions: Human-Robot Interactive Drawing</span>
                <br>
                <a href="https://yejin-kim.com/contact">Yejin Kim</a>, <strong>Dohyeok Lee</strong>
                <br>
                <em>CVPR Demo</em>, 2023 &nbsp <font color="red"><strong>(Best Demo)</strong></font>
                <br>
                <a href="https://github.com/ykim104/ARTE">code</a>
                <p></p>
                <p>
                  We created ARTE, <strong>a real-world human-robot collaborative</strong> drawing system with multi-modal goal-conditioned policy.
                  This work validates our generalization aprroaches in actual deployment, demonstrating robust performance across diverse drawing scenarios and human interaction patterns.
                </p>
              </td>
            </tr>
    <tr onmouseout="dyn_stop()" onmouseover="dyn_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='dyn_image'><img src='images/dyn_exp.gif' width="160" height="160"></div>
          <img src='images/dyn_concept figure_1.png' width="160" height="160">
        </div>
        <script type="text/javascript">
          function dyn_start() {
            document.getElementById('dyn_image').style.opacity = "1";
          }
        
          function dyn_stop() {
            document.getElementById('dyn_image').style.opacity = "0";
          }
          dyn_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://embodied-ai.org/cvpr2025/" id="MCG_journal">
          <span class="papertitle">Learning Generalizable Visuomotor Policy through Dynamics-Alignment</span>
        </a>
        <br>
        <strong>Dohyeok Lee</strong>, Jung Min Lee, Munkyung Kim, Seokhun Ju, Seungyub Han, Jin Woo Koo, Jungwoo Lee
        <br>
        <em>CVPR Embodied AI Workshop</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2510.27114">paper</a>
        <p></p>
        <p>
          We address <strong>temporal understanding</strong> by learning explicit dynamics and mutually correct dynamics models and policy by iterative flow generation. 
          Our key insight: <strong>random trajectory data</strong> (zero annotation cost) enables robust <strong>generalization beyond expert demonstrations</strong> to out-of-distribution scenarios.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/vi_figure.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://embodied-ai.org/cvpr2025/" id="MCG_journal">
          <span class="papertitle">View-Imagination: Enhancing Visuomotor Control with Adaptive View Synthesis</span>
        </a>
        <br>
        <strong>Dohyeok Lee</strong>, Munkyung Kim, Jung Min Lee, Seungyub Han, Jungwoo Lee
        <br>
        <em>CVPR Embodied AI Workshop</em>, 2025
        <br>
        <a href="data/vi_camera_ready.pdf">paper</a>
        <p></p>
        <p>
          We tackle <strong>spatial understanding</strong> challenges where fixed cameras fail during occlusions. 
          Our approach leverages <strong>novel view synthesis</strong> to generate optimal viewpoints, enabling robust <strong>generalization to unseen spatial configurations</strong> and visual ambiguities.

          We proposed View-Imagination, a novel framework that dynamically selects optimal camera viewpoints for robotic manipulation using adaptive view synthesis. 
          Based on our key insight that the most informative viewpoint is scene-dependent, View-Imagination trains a learnable viewpoint policy enabling robots to actively resolve visual ambiguities like occlusions.
        </p>
      </td>
    </tr>

    <tr onmouseout="furuta_stop()" onmouseover="furuta_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='furuta_image'><img src='images/furuta.gif' width="160" height="160"></div>
          <img src='images/furuta.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function furuta_start() {
            document.getElementById('furuta_image').style.opacity = "1";
          }
        
          function furuta_stop() {
            document.getElementById('furuta_image').style.opacity = "0";
          }
          furuta_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Control of Furuta Pendulum with Reinforcement Learning</span>
        <br>
        <strong>Dohyeok Lee</strong>, Usama Mohammad, Dong Eui Chang
        <br>
        <em>ICCAS</em>, 2019
        <br>
        <a href="https://www.youtube.com/watch?v=a6W6u8iMDU8&ab_channel=ControlLabKAIST">video</a>
        <p></p>
        <p>
          We implemented robust control for the Furuta pendulum with <strong>in-the-wild and sim2real training</strong> across diverse tasks.
          This work established our commitment to real-world robust RL agents.
        </p>
      </td>
    </tr> 
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:16px;width:100%;vertical-align:middle">
    <h2>Work Experience</h2>
    <p>
      Prior to my Ph.D., I gained hands-on robotics experience at two startups, building complete robotic systems from hardware to deployment. 
      This practical background informs my current research on making learning algorithms work reliably in real-world settings.
    </p>
  </td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:16px;width:80%;vertical-align:middle">
      <span class="papertitle">Robotics Engineer</span>
    <br>
    <a href="https://diveintothehive.com/">D.Hive</a> (startup), Daejeon, Korea
    <br>
    2020.10 - 2021.04
    <br>
    <p>
      <ul>
        <li>Built autonomous outdoor delivery robot from scratch, integrating sensor fusion for robust navigation in urban environments</li>
        <li>Led 10-engineer team across hardware/software, achieving successful deployment in real-world delivery scenarios</li>
      </ul>
    </p>
    </td>
  </tr>
  
  <tr>
    <td style="padding:16px;width:80%;vertical-align:middle">
      <span class="papertitle">Robotics Engineer Intern</span>
    <br>
    <a href="https://coops.bot/">Crazing Lab</a> (startup), Pangyo, Korea
    <br>
    2019.06 - 2019.08
    <br>
    <p>
      <ul>
        <li>Built autonomous filming robot: hardware (frame, battery system), BLDC motor control system, and UART communication system</li>
        <li>Implemented ROS system for motor control, IMU, LiDAR, and depth camera data processing</li>
      </ul>
    </p>
    </td>
  </tr>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:16px;width:100%;vertical-align:middle">
    <h2>Open Source Contribution</h2>
  </td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/impala.png" alt="PontTuset" width="160" style="border-style: none">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">IMPALA</span>
      <br>
      Open Source Contribution, 2024
      <br>
      <a href="https://github.com/dohyeoklee/IMPALA-distributed-RL">code</a>
      <p></p>
      <p>Implemented <a href="https://arxiv.org/abs/1802.01561">IMPALA</a>(Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures) in distributed system with ray, redis, and UDP</p>
    </td>
  </tr>

  <tr onmouseout="n_ctrl_stop()" onmouseover="n_ctrl_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='nctrl_image'><img src='images/nonlinear_ctrl.gif' width="160" height="160"></div>
        <img src='images/nonlinear_ctrl.png' width="160" height="160">
      </div>
      <script type="text/javascript">
        function n_ctrl_start() {
          document.getElementById('nctrl_image').style.opacity = "1";
        }
      
        function n_ctrl_stop() {
          document.getElementById('nctrl_image').style.opacity = "0";
        }
        n_ctrl_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Nonlinear Controller (★20)</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/Non-linear-control-simulator">code</a>
      <p></p>
      <p>Implemented nonlinear control (robust, adaptive, sliding mode) algorithms on two-arm manipulator simulator</p>
    </td>
  </tr>

  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/EKF.png" alt="PontTuset" width="160" height="160" style="border-style: none">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">EKF (★14)</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/EKF-kitti-GPS-IMU">code</a>
      <p></p>
      <p>Implemented EKF(Extended Kalman Filter) for sensor fusion of GPS and IMU data with Kitti dataset
    </td>
  </tr>

  <tr onmouseout="rrt_stop()" onmouseover="rrt_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='rrt_image'><img src='images/rrt.gif' width="160" height="160"></div>
        <img src='images/rrt.jpeg' width="160" height="160">
      </div>
      <script type="text/javascript">
        function rrt_start() {
          document.getElementById('rrt_image').style.opacity = "1";
        }
      
        function rrt_stop() {
          document.getElementById('rrt_image').style.opacity = "0";
        }
        rrt_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">RRT</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/RRT-python">code</a>
      <p></p>
      <p>Implemented RRT(Rapid Random Tree) algorithms
    </td>
  </tr>     


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>Robotics Project</h2>
    </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/humanoid.jpg" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Mobile Humanoid</span>
        <br>
        Course Project at SNU (Actuation and Sensing Mechanisms for Robots), 2024
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, and 23 students
        <br>
        <p></p>
        <p>Developed wheel-based humanoid for navigation and object manipulation</p>
      </td>
    </tr>

    <tr onmouseout="spot_stop()" onmouseover="spot_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='spot_image'><img src='images/spot.gif' width="160" height="160"></div>
          <img src='images/spot.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function spot_start() {
            document.getElementById('spot_image').style.opacity = "1";
          }
        
          function spot_stop() {
            document.getElementById('spot_image').style.opacity = "0";
          }
          spot_stop()
        </script>
      </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Robot-AR system</span>
      <br>
      In collaboration with Zer01ne(Hyundai Motor Company), 2021
      <br>
      Collaborator: <a href="https://minyoung.works/information">Minyoung Kim</a>, <a href="https://yejin-kim.com/contact">Yejin Kim</a>, <strong>Dohyeok Lee</strong>, Junyoung Kim, Sunho Chang
      <br>
      <a href="https://www.youtube.com/watch?v=ux7y3rQ4NdQ">video1</a> /
      <a href="https://vimeo.com/643065295">video2</a>
      <p></p>
      <p>Developed Unity-ROS pipeline for AR visualization of Boston Dynamics Spot, enabling intuitive robot control system</p>
    </td>
  </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/vender.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Vender</span>
        <br>
        In collaboration with Art Center Nabi, 2020
        <br>
        Collaborator: <a href="https://minyoung.works/information">Minyoung Kim</a>, <strong>Dohyeok Lee</strong>, <a href="https://seoseong.uk/">Seonguk Seo</a>, <a href="https://itsc.kr/">Taewon Kang</a>, Dahye Lee, Daeun Kim
        <br>
        <a href="https://www.youtube.com/watch?v=b-Zn6jU1vfc">video</a>
        <p></p>
        <p>Created AI media artwork with AI based emotion recognition and autonomous vending machine system</p>
      </td>
    </tr>

    <tr onmouseout="auto_stop()" onmouseover="auto_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='auto_image'><img src='images/auto.gif' width="160" height="160"></div>
          <img src='images/autonomous_robot.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function auto_start() {
            document.getElementById('auto_image').style.opacity = "1";
          }
        
          function auto_stop() {
            document.getElementById('auto_image').style.opacity = "0";
          }
          auto_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Autonomous Mobile Robot</span>
          <br>
          In collaboration with robotics club MR, KAIST, 2018
          <br>
          Collaborator: <strong>Dohyeok Lee</strong>, Inyub Kim, Yongmin Lee, Dokyun Lee
          <br>
          <a href="https://www.youtube.com/watch?v=HwjY57Dp25U">video</a>
          <br>
          <p></p>
          <p>
            Developed autonomous mobile robot with YOLO, Tmap API, GPS and compass sensor, etc.
          </p>
        </td>
    </tr>

    <tr onmouseout="tele_dex_stop()" onmouseover="tele_dex_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='tele_dex_image'><img src='images/teleop_dex_manipulator.gif' width="160" height="160"></div>
          <img src='images/teleop_dex_manipulator.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function tele_dex_start() {
            document.getElementById('tele_dex_image').style.opacity = "1";
          }
        
          function tele_dex_stop() {
            document.getElementById('tele_dex_image').style.opacity = "0";
          }
          tele_dex_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://mr.kaist.ac.kr/projects/70" id="MCG_journal">
          <span class="papertitle">Hand-shape Manipulator with Teleoperation</span>
        </a>
        <br>
        In collaboration with robotics club MR, KAIST, 2017
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, Jaemin Cho, Jinsub Lee, Kiheon Sung
        <br>
        <p></p>
        <p>Developed hand-shape manipulator and glove-shape interface for teleoperation</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/marker_robot_image_1.jpg" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://mr.kaist.ac.kr/projects/55" id="MCG_journal">
          <span class="papertitle">Marker-based Mobile Robot</span>
        </a>
        <br>
        In collaboration with robotics club MR, KAIST, 2016
        <br>
        Collaborator: Duckyu Choi, <a href="https://wjuni.com/">Hwijoon Lim</a>, <strong>Dohyeok Lee</strong>
        <br>
        <p></p>
        <p>Developed mobile robot for marker-based localization and mapping</p>
      </td>
    </tr>
	

	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>Other Research Project</h2>
    </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
   


    <tr onmouseout="iso_stop()" onmouseover="iso_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='iso_image'><img src='images/iso.gif' width="160" height="160"></div>
          <img src='images/iso.png' width="160" height="160">
        </div>
        <script type="text/javascript">
          function iso_start() {
            document.getElementById('iso_image').style.opacity = "1";
          }
        
          function iso_stop() {
            document.getElementById('iso_image').style.opacity = "0";
          }
          iso_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Minimum distortion embedding for RL</span>
        <br>
        Taehyun Cho, <strong>Dohyeok Lee</strong>, Jungwoo Lee
        <br>
        <em>KICS Winter Conference</em>, 2023
        <br>
        <a href="data/min_distorsion_RL.pdf">preprint</a> / 
        <a href="https://github.com/dohyeoklee/Manifold-Isometric-Regularization-RL">code</a>
        <p></p>
        <p>
          Proposed isometric regularization for RL to minimize distortion of latent space embedding
        </p>
      </td>
    </tr>

	  <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/sbe_dqn.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Separated batch ensemble DQN</span>
        <br>
        <strong>Dohyeok Lee</strong>, Jungwoo Lee
        <br>
        <em>KICS Winter Conference</em>, 2023
        <br>
        <a href="https://github.com/dohyeoklee/Sperated-Batch-Ensemble-DQN">code</a>
        <p></p>
        <p>
          Proposed separated batch ensemble DQN for diversification of ensemble using separated batch for Bellman Q-target
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/surf_decomp.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Genetic Algorithm for Surface Decomposition</span>
        <br>
        Research Project, 2022
        <br>
        <a href="https://github.com/dohyeoklee/surface-decomposition-genetic-algorithm">code</a>
        <p></p>
        <p>Implemented genetic algorithm for earth surface decomposition with arbitrary basis function</p>
      </td>
    </tr>


    <tr onmouseout="drone_stop()" onmouseover="drone_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='drone_image'><img src='images/Drone_RL_13x13_move.gif' width="160" height="160"></div>
          <img src='images/Drone_RL_13x13_move-0000.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function drone_start() {
            document.getElementById('drone_image').style.opacity = "1";
          }
        
          function drone_stop() {
            document.getElementById('drone_image').style.opacity = "0";
          }
          drone_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Simulator and Reinforcement Learning Algorithms for Surveillance/Reconnaissance</span>
        <br>
        Changsik Lee, <strong>Dohyeok Lee</strong>, Dong Eui Chang
        <br>
        <em>KIMST Conference</em>, 2020
        <br>
        <p></p>
        <p>Developed simulation environment for surveillance/reconnaissance and reinforcement learning algorithms for surveillance agent</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/3d_pose.png" alt="PontTuset" width="160" height="100" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">3D Box Fitting</span>
        <br>
        In collaboration with RCV KAIST, 2018
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, Jaekook Hyun
        <br>
        <p></p>
        <p>Developed 3D box fitting algorithm for given point cloud data, collaboration with Hubo lab</p>
      </td>
    </tr>
       

        
     <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:16px;width:80%;vertical-align:middle">
              Service: Reviewer for NeurIPS 2025, CoRL Workshop 2024, ITW 2024
            </td>	
           
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  template adapted from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
